<table>

<tr><td>
  
### ğŸ‘¨ğŸ»â€ğŸ’» About Me
<p>
  &emsp;&emsp;I am an incoming Ph.D. student at <b><a href="http://english.ia.cas.cn/"> Institute of Automation, Chinese Academy of Sciences (CASIA)</a></b>, supervised by <b><a href="https://people.ucas.ac.cn/~huangkaiqi?language=en">Prof. Kaiqi Huang</a></b> (IAPR Fellow) at <b><a href="http://www.crise.ia.ac.cn/">Center for Research on Intelligent System and Engineering (CRISE)</a></b>.
</p>
<p>
  &emsp;&emsp;Currently, I am a fourth-year undergraduate student majoring in Computer Science and Technology at <b><a href="https://scs.bupt.edu.cn/">School of Computer Science (SCS)</a></b> at <b><a href="https://www.bupt.edu.cn/">Beijing University of Posts and Telecommunications (BUPT)</a></b>.
</p>
<p>
  &emsp;&emsp;I am very grateful to work with <b><a href="https://huuuuusy.github.io/">Dr. Shiyu Hu</a></b>, which has a significant impact on me. I am also grateful to grow up and study with my twin brother Xuzhao Li, which is a truly unique and special experience for me.
</p>
<br>
</td></tr>

<tr><td>

### ğŸ”ï¸ Research

#### Visual Object Tracking (VOT)

- Research on visual object tracking algorithms within diverse scenes, aims to enhance the understanding and performance of single object tracking in various scenarios.
- Research on the robustness and generalization aspects of single object tracking algorithms, investigates the algorithms' ability to adapt across diverse scenarios, ensuring consistent and reliable performance.

#### Visual Language Tracking (VLT)

- Research on multi-modal tracking, addressing challenges related to integrating visual and linguistic information for improved tracking accuracy.
- Research on VLT extends to tasks involving comprehensive video understanding and encompasses efforts to enhance the algorithms' capability to interpret and contextualize objects in videos based on linguistic input.
- The exploration of human-computer interaction patterns employs Large Language Models (LLMs) in conjunction with visual language tracking as a proxy task, contributing to the development of interactions that are more intuitive and user-friendly.

<br>
</td></tr>

<tr><td>
  
### ğŸ”¥ News

- **2023.12** : ğŸ† Obtain **China National Scholarship** with a rank of **1/455 (0.22%)** (highest honor for undergraduates in China, awarded to top 1% students of BUPT)!
 
- **2023.09** : ğŸ“ One paper has been accepted by **the 37th Conference on Neural Information Processing Systems** (NeurIPS, CCF-A Conference, Poster)!

- **2022.12** : ğŸ† Obtain **China National Scholarship** with a rank of **2/430 (0.47%)** (highest honor for undergraduates in China, awarded to top 1% students of BUPT)!

<br>
</td></tr>

<tr><td>

### âš™ï¸ Maintained Projects

* **[VideoCube Platform](http://videocube.aitestunion.com/)** 
* **[SOTVerse Platform](http://metaverse.aitestunion.com/)**
* **[GOT-10k Platform](http://got-10k.aitestunion.com/)** 
* **[VideoCube Toolkit](https://github.com/huuuuusy/videocube-toolkit)**

<br>
</td></tr>

<tr><td>
  
### ğŸ”— For More Info

* **[Intelligence of Human-Computer Competition](http://turingai.ia.ac.cn/)**
* **[Research Group of Intelligent Gaming](http://www.ig.ia.ac.cn:81/)**
* **[Center for Research on Intelligent System and Engineering (CRISE)](http://www.crise.ia.ac.cn/)**
* **[Institute of Automation, Chinese Academy of Sciences (CASIA)](http://english.ia.cas.cn/)**
* **[University of Chinese Academy of Sciences (UCAS)](https://www.ucas.ac.cn/)**
* **[Beijing University of Posts and Telecommunications (BUPT)](https://www.bupt.edu.cn/)**

<br>
</td></tr>

<tr><td>
  
### âœ‰ï¸ Contact

* **lixuchen2024@ia.ac.cn** (Main, Valid from 2023.10 - 2029.07)
* **xuchenli@bupt.edu.cn** (Valid from 2020.09 - 2024.07)
* **xuchenli1030@gmail.com**

<br>
</td></tr>
</table>
