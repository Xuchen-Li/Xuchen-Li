<img src="https://github.com/Xuchen-Li/Xuchen-Li/blob/output/github-contribution-grid-snake.svg" alt="è´¡çŒ®ç½‘æ ¼å›¾" style="display: block; margin: 0 auto;">

<table>
 
<tr><td>

### ğŸ‘¨ğŸ»â€ğŸ’» About Me
<p>
  &emsp;&emsp;I am <b>Xuchen Li <font face="æ¥·ä½“">(ææ—­å®¸)</font></b>, an incoming Ph.D. student at <b><a href="http://english.ia.cas.cn/"> Institute of Automation, Chinese Academy of Sciences (CASIA)</a></b>, supervised by <b><a href="https://people.ucas.ac.cn/~huangkaiqi?language=en">Prof. Kaiqi Huang</a></b> (IAPR Fellow). Additionally, I am a member of <b><a href="http://viig.aitestunion.com/">Visual Intelligence Interest Group (VIIG)</a></b>.
</p>
<p>
  &emsp;&emsp;Currently, I am a fourth-year undergraduate student majoring in Computer Science and Technology at <b><a href="https://scs.bupt.edu.cn/">School of Computer Science (SCS)</a></b> at <b><a href="https://www.bupt.edu.cn/">Beijing University of Posts and Telecommunications (BUPT)</a></b>.
</p>
<p>
  &emsp;&emsp;I am very grateful to work with <b><a href="https://huuuuusy.github.io/">Dr. Shiyu Hu</a></b>, which has a significant impact on me. I am also grateful to grow up and study with my twin brother <b><a href="https://xuzhaoli.github.io/">Xuzhao Li</a></b>, which is a truly unique and special experience for me.
</p>
<p>
  &emsp;&emsp;My research focuses on visual object tracking and visual language tracking tasks. If you are interested in my work or would like to collaborate, please feel free to contact me.
</p>

<br>
</td></tr>

<tr><td>

### ğŸ”¬ Research Interests

#### Visual Language Tracking (VLT)

- Research on multi-modal tracking, addressing challenges related to integrating visual and linguistic information for improved tracking accuracy.
- Research on VLT extends to tasks involving comprehensive video understanding and encompasses efforts to enhance the algorithms' capability to interpret and contextualize objects in videos based on linguistic input.
- The exploration of human-computer interaction patterns employs Large Language Models (LLMs) in conjunction with visual language tracking as a proxy task, contributing to the development of interactions that are more intuitive and user-friendly.

#### Visual Object Tracking (VOT)

- Research on visual object tracking algorithms within diverse scenes, aims to enhance the understanding and performance of single object tracking in various scenarios.
- Research on the robustness and generalization aspects of single object tracking algorithms, investigates the algorithms' ability to adapt across diverse scenarios, ensuring consistent and reliable performance.

<br>
</td></tr>

<tr><td>

### ğŸ”¥ News

- **2024.04**: ğŸ“ One paper has been accepted by **the 3rd CVPR Workshop on Vision Datasets Understanding and DataCV Challenge** as **Oral Presentation** (CVPRW, Workshop in CCF-A Conference, Oral)!

- **2023.12**: ğŸ† Obtain **College Scholarship of University of Chinese Academy of Sciences (ä¸­å›½ç§‘å­¦é™¢å¤§å­¦å¤§å­¦ç”Ÿå¥–å­¦é‡‘)** (only 17 students win this scholarship of CASIA)!
  
- **2023.12**: ğŸ† Obtain **China National Scholarship (æœ¬ç§‘ç”Ÿå›½å®¶å¥–å­¦é‡‘)** with a rank of **1/455 (0.22%)** (the highest honor for undergraduates in China, awarded to top 1% students of BUPT)!
  
- **2023.11**: ğŸ† Obtain **Beijing Merit Student (åŒ—äº¬å¸‚ä¸‰å¥½å­¦ç”Ÿ)** (only 36 students obtain this honor of BUPT)!
  
- **2023.09**: ğŸ“ One paper has been accepted by **the 37th Conference on Neural Information Processing Systems** (NeurIPS, CCF-A Conference, Poster)!
  
- **2022.12**: ğŸ† Obtain **Huawei AI Education Base Scholarship (åä¸ºæ™ºèƒ½åŸºåº§å¥–å­¦é‡‘)** (only 20 students win this scholarship of BUPT)!
  
- **2022.12**: ğŸ† Obtain **China National Scholarship (æœ¬ç§‘ç”Ÿå›½å®¶å¥–å­¦é‡‘)** with a rank of **2/430 (0.47%)** (the highest honor for undergraduates in China, awarded to top 1% students of BUPT)!


<br>
</td></tr>

</table>

<div markdown="1">
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5r8trq06pja&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>
</div>
